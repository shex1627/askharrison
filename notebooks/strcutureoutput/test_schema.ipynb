{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from askharrison.llmparse.schema_recommender import SchemaGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from askharrison.llm.openai_llm_client import OpenAIClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_client = OpenAIClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_generator = SchemaGenerator(openai_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = schema_generator.generate_schema_from_description(\"generate a qa schema from chat history of a support chat channel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from askharrison.llm_models import extract_python_code, safe_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = schema_generator._create_pydantic_model(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'properties': {'raw_text': {'description': 'Original text that generated this output',\n",
       "   'title': 'Raw Text',\n",
       "   'type': 'string'},\n",
       "  'extracted_at': {'format': 'date-time',\n",
       "   'title': 'Extracted At',\n",
       "   'type': 'string'},\n",
       "  'chatId': {'default': None,\n",
       "   'description': 'Unique identifier for the chat session',\n",
       "   'title': 'Chatid',\n",
       "   'type': 'string'},\n",
       "  'timestamp': {'default': None,\n",
       "   'description': 'Timestamp when the chat occurred',\n",
       "   'title': 'Timestamp',\n",
       "   'type': 'string'},\n",
       "  'customerId': {'default': None,\n",
       "   'description': 'Unique identifier for the customer',\n",
       "   'title': 'Customerid',\n",
       "   'type': 'string'},\n",
       "  'agentId': {'default': None,\n",
       "   'description': 'Unique identifier for the support agent',\n",
       "   'title': 'Agentid',\n",
       "   'type': 'string'},\n",
       "  'questions': {'default': None,\n",
       "   'description': 'List of questions asked during the chat',\n",
       "   'items': {},\n",
       "   'title': 'Questions',\n",
       "   'type': 'array'},\n",
       "  'answers': {'default': None,\n",
       "   'description': 'List of answers provided during the chat',\n",
       "   'items': {},\n",
       "   'title': 'Answers',\n",
       "   'type': 'array'},\n",
       "  'chatDuration': {'default': None,\n",
       "   'description': 'Total duration of the chat in seconds',\n",
       "   'title': 'Chatduration',\n",
       "   'type': 'integer'},\n",
       "  'chatStatus': {'default': None,\n",
       "   'description': 'Status of the chat (e.g., completed, pending, escalated)',\n",
       "   'title': 'Chatstatus',\n",
       "   'type': 'string'}},\n",
       " 'required': ['raw_text'],\n",
       " 'title': 'SupportChatQA',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "json.loads(model.schema_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "output2 = schema_generator.generate_schema_from_description(\"\"\"generate a qa schema from chat history of a support chat channel\n",
    "                                                        The schema should have a field for the question and a field for the answer or resolution\n",
    "                                                        answer is null if the question is not answered\n",
    "                                                        also include start_date and end_date\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"C:\\\\Users\\\\alist\\\\Desktop\\\\code\\\\askharrison\\\\notebooks\\\\data\\\\cc_features.txt\") as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommended_output = schema_generator.recommend_schema_from_document(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'introduction': {'type': 'string',\n",
       "  'description': 'Introduction of the release notes document.'},\n",
       " 'oldReleasesReference': {'type': 'string',\n",
       "  'description': 'URL or reference to older releases.'},\n",
       " 'updates': {'type': 'array',\n",
       "  'description': 'List of updates or features in the release notes.',\n",
       "  'items': {'type': 'object',\n",
       "   'properties': {'date': {'type': 'string',\n",
       "     'format': 'date',\n",
       "     'description': 'The date of the update or announcement.'},\n",
       "    'title': {'type': 'string',\n",
       "     'description': 'Title summarizing the update or new feature.'},\n",
       "    'description': {'type': 'string',\n",
       "     'description': 'Detailed description of the update or feature.'},\n",
       "    'externalReferences': {'type': 'array',\n",
       "     'description': 'References to external documents or resources.',\n",
       "     'items': {'type': 'string'}}},\n",
       "   'required': ['date', 'title', 'description']}}}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommended_output['properties']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"C:\\\\Users\\\\alist\\\\Desktop\\\\code\\\\askharrison\\\\askharrison\\\\llm_models.py\") as f:\n",
    "    codefile = f.read()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_recommended_output = schema_generator.recommend_schema_from_document(codefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': 'Schema for parsing documents containing utility functions for language model processing in Python.',\n",
       " 'schema': {'imports': {'description': 'List of import statements with associated modules or packages used.',\n",
       "   'type': 'array',\n",
       "   'items': {'type': 'string'}},\n",
       "  'functions': {'description': 'List of function definitions in the document.',\n",
       "   'type': 'array',\n",
       "   'items': {'type': 'object',\n",
       "    'properties': {'name': {'description': 'Name of the function.',\n",
       "      'type': 'string'},\n",
       "     'description': {'description': 'Docstring description explaining the purpose of the function.',\n",
       "      'type': 'string'},\n",
       "     'parameters': {'description': 'List of parameters the function takes, with their descriptions.',\n",
       "      'type': 'array',\n",
       "      'items': {'type': 'object',\n",
       "       'properties': {'name': {'description': 'Parameter name.',\n",
       "         'type': 'string'},\n",
       "        'type': {'description': 'Type of the parameter.', 'type': 'string'},\n",
       "        'description': {'description': \"Description of the parameter's purpose.\",\n",
       "         'type': 'string'},\n",
       "        'default': {'description': 'Default value for the parameter, if any.',\n",
       "         'type': 'string',\n",
       "         'nullable': True}},\n",
       "       'required': ['name', 'type', 'description']}},\n",
       "     'returns': {'description': 'Description of the return value of the function.',\n",
       "      'type': 'string'}},\n",
       "    'required': ['name', 'description', 'parameters', 'returns']}}}}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "safe_eval(extract_python_code(code_recommended_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "codefile_schama_dict = json.loads(extract_python_code(code_recommended_output))\n",
    "\n",
    "# create a pydantic model from the schema without using the schema generator\n",
    "from pydantic import BaseModel\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "pydantic_output = openai_client.generate(f\"\"\"generate a pydantic models from the schema below\n",
    "                       {codefile_schama_dict}\"\n",
    "                       return only python code for the pydantic model,\n",
    "                       example output:\n",
    "                       ####\n",
    "                       ```python\n",
    "                       class MyModel(BaseModel):\n",
    "                            field1: str\n",
    "                            field2: int\n",
    "                       \n",
    "                       class MyModel2(BaseModel):\n",
    "                            field1: MyModel\n",
    "                            field2: int\n",
    "                       ```\n",
    "                       ####\n",
    "                       output\n",
    "                       \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from typing import List, Optional\n",
      "from pydantic import BaseModel\n",
      "\n",
      "class Parameter(BaseModel):\n",
      "    name: str\n",
      "    type: str\n",
      "    description: str\n",
      "    default: Optional[str] = None\n",
      "\n",
      "class Function(BaseModel):\n",
      "    name: str\n",
      "    description: str\n",
      "    parameters: List[Parameter]\n",
      "    returns: str\n",
      "\n",
      "class Schema(BaseModel):\n",
      "    imports: List[str]\n",
      "    functions: List[Function]\n"
     ]
    }
   ],
   "source": [
    "print(extract_python_code(pydantic_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from askharrison.llmparse.document_parser import DocumentParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_parser = DocumentParser(openai_client) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid JSON in LLM response, returning raw response\n"
     ]
    }
   ],
   "source": [
    "doc_parsed_output = document_parser.parse_document(codefile, codefile_schama_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'imports': ['requests',\n",
       "  'pandas as pd',\n",
       "  'typing.List',\n",
       "  'typing.Dict',\n",
       "  'typing.Any',\n",
       "  'typing.Callable',\n",
       "  'typing.Optional',\n",
       "  'openai.OpenAI',\n",
       "  're',\n",
       "  'concurrent.futures',\n",
       "  'time',\n",
       "  'random',\n",
       "  'tqdm.tqdm',\n",
       "  'functools',\n",
       "  'tiktoken'],\n",
       " 'functions': [{'name': 'process_question',\n",
       "   'description': 'Processes a question using the specified language model and returns the response.',\n",
       "   'parameters': {'question': 'str', 'model': 'str, optional'},\n",
       "   'returns': 'str'},\n",
       "  {'name': 'polish_code',\n",
       "   'description': \"Polish the code by removing the leading 'python' or 'py', removing surrounding '`' characters and removing trailing spaces and new lines.\",\n",
       "   'parameters': {'code': 'str'},\n",
       "   'returns': 'str'},\n",
       "  {'name': 'extract_python_code',\n",
       "   'description': 'Extract the code from the llm response.',\n",
       "   'parameters': {'response': 'str', 'separator': 'str, optional'},\n",
       "   'returns': 'str'},\n",
       "  {'name': 'safe_eval',\n",
       "   'description': 'Evaluates a string expression safely, returning a default output if an error occurs.',\n",
       "   'parameters': {'input_str': 'str', 'default_output': 'Any, optional'},\n",
       "   'returns': 'Any'},\n",
       "  {'name': 'parallel_llm_processor',\n",
       "   'description': 'Process a list of LLM prompts in parallel, submitting each prompt individually.',\n",
       "   'parameters': {'prompts': 'List[str]',\n",
       "    'llm_function': 'Callable[[str], Any]',\n",
       "    'max_workers': 'int'},\n",
       "   'returns': 'List of results from LLM processing'},\n",
       "  {'name': 'chunk_llm_input',\n",
       "   'description': 'Decorator to chunk input into smaller pieces based on token count before passing it to the decorated function.',\n",
       "   'parameters': {'max_tokens': 'int', 'encoding_name': 'str'},\n",
       "   'returns': 'Decorator function'},\n",
       "  {'name': 'chunk_text_input',\n",
       "   'description': 'Decorator to chunk a large text input into smaller pieces based on token count.',\n",
       "   'parameters': {'max_tokens': 'int', 'encoding_name': 'str'},\n",
       "   'returns': 'List[str]'}]}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "safe_eval(extract_python_code(doc_parsed_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
