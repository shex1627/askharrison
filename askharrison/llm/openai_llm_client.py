from openai import OpenAI
from askharrison.llm.llm_client import LLMClient

class OpenAIClient(LLMClient):
    def __init__(self, api_key: str):
        if not api_key:
            self.client = OpenAI()
        else:
            self.client = OpenAI(api_key=api_key)

    def generate(self, question: str, model: str = 'gpt-4o', messages=[]) -> str:
        """
        Processes a question using the specified language model and returns the response.

        Args:
            question (str): The question to be processed by the language model.
            model (str, optional): The model to be used for processing the question. Defaults to 'gpt-4o'.

        Returns:
            str: The response generated by the language model.
        """
        if not messages:
            messages = [
                {"role": "system", "content": "You are a helpful assistant"},
                {"role": "user", "content": question}
            ]
        else:
            messages.append({"role": "user", "content": question})
        response = self.client.chat.completions.create(
            model=model,
            messages=messages
        )
        return response.choices[0].message.content
        
    async def async_generate(self, question: str, model: str = 'gpt-4o', messages=[]) -> str:
        """
        Processes a question using the specified language model and returns the response.

        Args:
            question (str): The question to be processed by the language model.
            model (str, optional): The model to be used for processing the question. Defaults to 'gpt-4o'.

        Returns:
            str: The response generated by the language model.
        """
        if not messages:
            messages = [
                {"role": "system", "content": "You are a helpful assistant"},
                {"role": "user", "content": question}
            ]
        else:
            messages.append({"role": "user", "content": question})
        response = self.client.chat.completions.create(
            model=model,
            messages=messages
        )
        return response.choices[0].message.content