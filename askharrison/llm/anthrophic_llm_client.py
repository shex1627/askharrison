import anthropic
from askharrison.llm.llm_client import LLMClient

class AnthropicAIClient(LLMClient):
    def __init__(self, api_key: str=None):
        if not api_key:
            self.client = client = anthropic.Anthropic()
        else:
            self.client = anthropic.Anthropic(
            api_key=api_key,
        )

    def generate(self, question: str, model: str = 'claude-3-5-sonnet-20241022', 
                 max_token=2048,
                 messages=[],
                 raw=False) -> str:
        """
        Processes a question using the specified language model and returns the response.

        Args:
            question (str): The question to be processed by the language model.
            model (str, optional): The model to be used for processing the question. Defaults to 'gpt-4o'.

        Returns:
            str: The response generated by the language model.

        role can be user, assistant
        """
        if not messages:
            messages = [
                {"role": "user", "content": question}
            ]
        else:
            messages.append({"role": "user", "content": question})
        response = self.client.messages.create(
            model=model,
            max_tokens=max_token,
            messages=messages
        )
        if raw:
            return response
        return response.content[0].text

